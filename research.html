<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

<head>
 <meta http-equiv="content-type" content="text/html; charset=utf-8" />
 <title>Research</title>
 <meta name="author" content="Alexandre Rademaker" />
 <link href="http://feeds.feedburner.com/arademaker" rel="alternate" title="Alexandre Rademaker" type="application/atom+xml" />
 
 <!-- syntax highlighting CSS -->
 <link rel="stylesheet" href="/css/syntax.css" type="text/css" />

 <!-- <link href="/css/highlight.css" rel="stylesheet" type="text/css"> -->
 <link href="/css/gists.css" rel="stylesheet" type="text/css"/>

 <!-- Homepage CSS -->
 <link rel="stylesheet" href="/css/screen.css" type="text/css" media="screen, projection" />

 <!-- Typekit 
 <script type="text/javascript" src="http://use.typekit.com/jpd0pfm.js"></script>
 <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
 -->

 <link href='http://fonts.googleapis.com/css?family=Inconsolata' rel='stylesheet' type='text/css'>



<!-- Google Analytics -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-97240-6']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body>
  <div id="fb-root"></div>
  <script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));</script>
  <div id="outer">

    <div id="top"></div>

    <div id="left">
      <img src="/images/eu-sf.jpg"/>
    </div>  

    <div class="site">
      <div class="title">
	<a href="/">Alexandre Rademaker</a>
	<a class="extra" href="/">home</a>
	<a class="extra" href="/about.html">about me</a>
	<a class="extra" href="/publications/index.html">publications</a>
        <a class="extra" href="/research.html">research</a>
      </div>
      
      <h1>Research</h1>

<p>My areas of interesting include logics (proof theory, model theory,
automatic theorem provers etc), knowledge representation and
reasoning, Semantic Web, programming languages (specially funcional
programming) etc.</p>

<p>More specifically I can enumerate the following areas that I would
like to work with:</p>

<ul>
<li>Ontology Alignment and Instance Matching: I would like to look again
to previous work with Edward Hermann and Isabel Cafezeiro maybe
applying to the WordNet-PT construction.</li>
</ul>


<p>Below I present (in Portuguese) some proposal of thesis research that
I would be interested in supervise.</p>

<h2>Em geral...</h2>

<p>Em todas as propostas abaixo, estou interessado tanto nos aspectos
teóricos quanto práticos. Tenho especial interesse na implementação
das soluções na forma de bibliotecas ou sistemas opensource. Dentre as
linguagens de programação que conheço, tenho especial interesse em
Lisp e seus dialetos e <a href="http://www.r-project.org/">R</a>. As razões para
escolha de Lisp são várias, dentre elas:</p>

<ul>
<li><p>Uma linguagem madura e bastante poderosa. Sugiro a leitura de
<a href="http://www.paulgraham.com/avg.html">Beating the Averages</a> e
<a href="http://www.paulgraham.com/rootsoflisp.html">The roots of Lisp</a>. Recentemente,
dois novos livros sobre a linguagem fizeram grande sucesso:
<a href="http://www.gigamonkeys.com/book/">Practical Common Lisp</a> e
<a href="http://landoflisp.com/">The Land of Lisp</a>. Isto aliado ao fato das
linguagens funcionais voltarem a chamar grande atenção por seus
benefícios em arquiteturas distribuídas.</p></li>
<li><p>Existe grande demanda na comunidade Lisp por bibliotecas e
ferramentas para trabalhar com RDF, OWL e outras tecnologias da Web
Semântica. Existem congressos específicos de Lisp e Web Semântica
que seriam fóruns naturais para publicações (vide
<a href="http://european-lisp-symposium.org/">European Lisp Symposium</a>).</p></li>
</ul>


<h2>Dicionário Histórico Brasileiro (CPDOC)</h2>

<p>O projeto do <a href="http://cpdoc.fgv.br/acervo/dhbb">DHBB</a> começou a ser
desenvolvido no CPDOC-FGV em 1974. A primeira edição do DHBB em 1984
consistia em quatro volumes e 4.493 verbetes. Em 2010, uma nova versão
do Dicionário pôde ser oferecida na web, com acesso gratuito e aberto,
com 7.553 verbetes, sendo 6.584 de natureza biográfica e 969 verbetes
temáticos, relativos a instituições, eventos e conceitos de interesse
para a história do Brasil pós-1930.</p>

<p>No final de 2010, EMAp e CPDOC iniciaram um projeto conjunto chamado
MIST. O objetivo do projeto é melhorar a qualidade dos dados do CPDOC
e incrementar as possibilidades de busca e navegação pelas
informações. O projeto MIST logo foi desmembrado em 3 sub projetos em
função do formato das informações e competências da equipe da EMAp:
texto, som e imagens.</p>

<p>Na parte texto, onde estou envolvido, meu interesse é utilizar
técnicas de processamento de linguagem natural (NLP) para: extração de
entidades nomeadas nos verbetes do HDBB, link do DHBB com outras
fontes de dados como Wikipedia, "triplificação" do DHBB etc.</p>

<p>Utilizar NLP para textos em português, no entanto, requer ainda um
grande esforço de construção de bases de dados para a lingua
portuguesa, como WordNet, VerbNet, NOMLEX etc. Sem contar recursos
mais custosos como uma gramática do português. Com tais bases de
dados, técnicas de processamento usadas em outras linguas podem então
ser aproveitas também para processamento de textos em português.</p>

<p>Constituem assim possíveis temas de pesquisa neste contexto:</p>

<ul>
<li><p>Contribuir no projeto já iniciado da construção da WordNet
brasileira, chamada WordNet-PT. Esta etapa envolve desafios como:
desenvolver métricas para medir a qualidade da base, desenvolvimento
de ferramentas para auxiliar no esforço colaborativo de traduação e
avaliação da tradução da WordNet em inglês para a portuguesa.</p></li>
<li><p>Idem para outras bases como VerbNet, SUMO, NOMLEX etc.</p></li>
<li><p>Pesquisar o problema e desenvolver a extração de entidades nomeadas
dos verbetes do DHBB com objetivo de: (1) descobrir links entre
verbetes; (2) conectar o DHBB a outras fontes como a Wikipedia e
outras ontologias como a MENTA.</p></li>
</ul>


<p>Outros temas são possíveis de serem desenvolvidos.</p>

<h2>Semantic Lattes</h2>

<p>A <a href="http://lattes.cnpq.br/">plataforma Lattes</a> é um sistema e banco de
dados desenvolvidos pelo CNPq para armazenar todos os currículos dos
pesquisadores brasileiros. Como todos os pedidos de financiamento à
agências de fomento à pesquisas, em todas as esferas de governo no
Brasil, atualmente exigem a apresentação do Lattes pelos pesquisadores
como parte das solicitações de financiamento, a plataforma tournou-se
um importante banco de dados com mais de 1 milhão de currículos vitae
cadastrados. Analisando os dados desta plataforma, pode-se obter um
importante panorama da pesquisa e pesquisadores no Brasil. Do ponto de
vista das instituições de pesquisa e ensino brasileiras, os Lattes de
seus pesquisadores constituem uma base de dados pronta para ser usada
para avaliação de desempenho e tomadas de decisões. O CNPq permite que
as instituições, após assinatura de um acordo, tenham acesso aos
currículos de seus pesquisadores. O desafio é, após a recuperação dos
dados, a consolidação, identificação de inconsistências e duplicatas e
correção dos erros. No entanto, todos estes desafios valem o esforço
se considerarmos o custo das instituições em tentarem desenvolver
sistemas de informação próprios que irão invariavelmente dobrar os
esforços dos pesquisadores na alimentação dos dados, gerando mais
inconsistências e possível baixa qualidade nos dados.</p>

<p>Consistituem possíveis temas de pesquisa nesta área:</p>

<ul>
<li><p>Melhorias no mapeamento do modelo de dados do LATTES para
RDF. Atualmente, no projeto
<a href="github.com/arademaker/SLattes">Semantic Lattes</a> já temos boa parte
dos dados dos CVs mapeados para RDF, utilizando ontologias
conhecidas como: FOAF, BIBO e SKOS. Mas ainda restam áreas dos CVs
não mapeadas.</p></li>
<li><p>Desenvolver técnicas, algorítmos e softwares para melhorar a
consolidação dos dados, identificação e relatório de
inconsistências, redundâncias e outros problemas na qualidade dos
dados.</p></li>
<li><p>Implementar bibliotecas de software para mining dos dados agregados
em RDF a partir de diversas fontes como: os CV Lattes, CAPES Qualis,
<a href="http://www.geonames.org/">Geonames Ontology</a> etc.</p></li>
</ul>


<h2>Logics and Law</h2>

<p>Lógicas descritivas clássicas têm sido amplamente utilizadas como base
para ontologias e inferências lógicas nos mais diversos domínios de
conhecimento. Uma ontologia é uma teoria lógica, isto é, um conjunto
de axiomas em uma linguagem lógica como ALC ou iALC. Não estamos
interessados na interpretação filosófica do termo. Estamos
particularmente interessados em um domínio específico, a inteligência
artificial voltada ao âmbito jurídico. Como em qualquer outro domínio,
a consistência é uma questão importante.  Entretanto, devido às
características normativas que lhes são intrínsecas, a consistência em
ontologias jurídicas é mais complexa que em outros domínios.</p>

<p>Preservar a consistência, isto é, ausência de contradições lógicas,
aparenta ser de mais difícil manutenção quando mais de uma lei pode
ser aplicada para julgar um mesmo caso, isso é, quando há conflito de
leis. Há alguns mecanismos para a resolução desse tipo de conflito,
como a determinação de foro privilegiado e jurisprudência. Na maioria
dos casos, isso se resolve através da determinação de uma hierarquia
de leis (precedência de leis). Mas mesmo com esses mecanismos, a
consistência ainda é o maior desafio nos sistemas jurídicos. Cada
nível da hierarquia precisa ser consistente e, como a consistência é
uma consequência direta de como se lida com a negação lógica, a
negação também é um grande problema nesses sistemas.</p>

<p>A negação e a a subsunção tem um papel decisivo na consistência de
ontologias. Uma semântica intuicionista adequada para a negação no
domínio jurídico surge ao se tomar os argumentos válidos,
individualmente, os habitantes da ontologia jurídica. Isso permite
lidarmos de forma elegante com situações de consistência jurídica,
como conflito de leis, tais quais os resolvidos pela análise de leis
do direito privado internacional.</p>

<p>Em colaboração com outros pesquisadores, tenho um projeto que visa
apresentar de forma resumida uma versão intuicionista da lógica
descritiva clássica
<a href="http://en.wikipedia.org/wiki/Description_logic">ALC</a>. Esta lógica,
denominada iALC, foi criada recentemente como extensão da
minha tese de doutorado. Fundamentada na teoria Kelseniana do Direito,
esta lógica vem sendo apresentada juntamente com aplicações ao Direito
Privado Internacional em diversos forums acadêmicos, incluindo
congressos de Lógica Híbrida, de Inteligência Artificial, Informática
e Direito. Neste projeto, discutem-se os fundamentos da teoria
jurídica do sistema apresentado e apresenta-se um exemplo de como
efetuar a análise de consistência de um ``conflito de leis no espaço''
utilizando o sistema dedutivo criado para iALC.</p>

<p>Constituem possíveis temas de pesquisa:</p>

<ul>
<li><p>Testar a abordagem e escalabilidade com o uso de casos reais que
estão a disposição no site do Supremo Tribunal Federal, como estudos
no âmbito de leis do Direito Internacional e verificar se a sentença
é compatível com uma das possíveis de serem obtidas pela análise
formal do caso jurídico.</p></li>
<li><p>Investigar os chamados "casos difíceis", onde a aplicação de
diferentes leis induzem ao impasse de uma sentença jurídica.</p></li>
<li><p>Projetar e construir uma ferramenta de edição de prova de teoremas.</p></li>
<li><p>Integrar a ferramenta de edição de prova de teoremas a um provador
automático de teoremas.</p></li>
<li><p>Projetar e construir um módulo para suporte a seleção de estratégias
de provas.</p></li>
<li><p>Projetar e construir um módulo para geração de explicação de provas
produzidas pelo provador de teoremas.</p></li>
<li><p>Integrar o provador a um editor de ontologias como, por exemplo, o
Protégé.</p></li>
</ul>


<h2>Outros Projetos</h2>

<p>Outros possíveis projetos estão relacionados a diversas idéias de
implementação de bibliotecas e pacotes para Lisp e R direta ou
indiretamente relacionados aos temas acima. Na medida do possivel,
tentarei futuramente enumerar cada uma das idéias que tenho.</p>

<h2>Comentários</h2>

<div id="disqus_thread"></div>


<script type="text/javascript">
    var disqus_shortname = 'arademaker'; 

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>


<p><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></p>


      <div class="footer">
	<div class="contact">
	  <p>
            Alexandre Rademaker<br />
            Professor at <a href="http://emap.fgv.br/">EMAp/FGV</a><br />
            arademaker AT gmail DOT com
	  </p>
	</div>
	<div class="contact">
	  <p>
        <a href="http://github.com/arademaker/">github.com/arademaker</a><br />
        <a href="http://twitter.com/arademaker/">twitter.com/arademaker</a><br />
        <a href="http://facebook.com/alexandre.rademaker">Facebook</a>
	  </p>
	</div>
	<div class="rss">
	  <a href="http://feeds.feedburner.com/arademaker">
            <img src="/images/rss.png" alt="Subscribe to RSS Feed" />
	  </a>
	</div>
      </div>
    </div>

    <div id="right">
    </div>
  </div>
</body>
</html>

